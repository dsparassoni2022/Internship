{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8629f137",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. \n",
    "You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10\n",
    "jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4660f369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\admin\\anaconda3\\lib\\site-packages (4.9.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (2022.9.14)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (1.26.11)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (0.10.2)\n",
      "Requirement already satisfied: idna in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.1.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\admin\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "574bb842",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3985e8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Admin\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e8ab57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "359dec0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the naukri page on automated chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01f7e2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering designation and location as required in the question-\n",
    "designation = driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "designation.send_keys('Data Analyst')\n",
    "\n",
    "location = driver.find_element(By.XPATH,\"/html/body/div[1]/div[7]/div/div/div[5]/div/div/div/div[1]/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0edce35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93cd81a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make empty list\n",
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "experience_required  = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a71d79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping Job title from the given page\n",
    "title_tags = driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title = i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "#scraping Job location from the given page\n",
    "location_tags = driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location = i.text\n",
    "    job_location.append(location)\n",
    "\n",
    "#scraping company name from the given page\n",
    "company_tags = driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in company_tags[0:10]:\n",
    "    company = i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "#scraping Job experience from the given page\n",
    "experience_tags = driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience = i.text\n",
    "    experience_required.append(experience)\n",
    "                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c722ad4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title))\n",
    "print(len(job_location))\n",
    "print(len(company_name))\n",
    "print(len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55be84ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Target</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tech Data Analyst</td>\n",
       "      <td>Hybrid - Bangalore/ Bengaluru, Karnataka, Gurg...</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/ Bengaluru, Karnataka</td>\n",
       "      <td>Artech</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Brunel</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Celonis &amp; Salesforce Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Chennai</td>\n",
       "      <td>Hitachi Energy</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Celonis &amp; Salesforce Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Hitachi Ltd.</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru</td>\n",
       "      <td>HARMAN</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru, Delhi / NCR</td>\n",
       "      <td>Aon</td>\n",
       "      <td>6-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru, Delhi / NCR</td>\n",
       "      <td>Aon</td>\n",
       "      <td>6-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...</td>\n",
       "      <td>Tata Consultancy Services (TCS)</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Job Title  \\\n",
       "0                       Data Analyst   \n",
       "1                  Tech Data Analyst   \n",
       "2                       Data Analyst   \n",
       "3                       Data Analyst   \n",
       "4  Celonis & Salesforce Data Analyst   \n",
       "5  Celonis & Salesforce Data Analyst   \n",
       "6                       Data Analyst   \n",
       "7                       Data Analyst   \n",
       "8                       Data Analyst   \n",
       "9                       Data Analyst   \n",
       "\n",
       "                                        Job Location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1  Hybrid - Bangalore/ Bengaluru, Karnataka, Gurg...   \n",
       "2                    Bangalore/ Bengaluru, Karnataka   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                       Bangalore/Bengaluru, Chennai   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                       Hybrid - Bangalore/Bengaluru   \n",
       "7          Hybrid - Bangalore/Bengaluru, Delhi / NCR   \n",
       "8          Hybrid - Bangalore/Bengaluru, Delhi / NCR   \n",
       "9  Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...   \n",
       "\n",
       "                      Company Name Experience  \n",
       "0                           Target    2-4 Yrs  \n",
       "1                            Wipro    3-6 Yrs  \n",
       "2                           Artech    5-8 Yrs  \n",
       "3                           Brunel    4-6 Yrs  \n",
       "4                   Hitachi Energy    3-6 Yrs  \n",
       "5                     Hitachi Ltd.    2-7 Yrs  \n",
       "6                           HARMAN    3-5 Yrs  \n",
       "7                              Aon    6-9 Yrs  \n",
       "8                              Aon    6-9 Yrs  \n",
       "9  Tata Consultancy Services (TCS)   5-10 Yrs  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a DataFrame for scraped data\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Job Title':job_title,'Job Location':job_location,'Company Name':company_name,'Experience':experience_required})\n",
    "df\n",
    "\n",
    "#quit the chrome window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165b3f08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1e6b72f",
   "metadata": {},
   "source": [
    "# Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. \n",
    "You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results youget.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44223508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83fab54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Admin\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "629d7c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cabc4762",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the naukri page on automated chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b45d6190",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering designation and location as required in the question-\n",
    "designation = driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "designation.send_keys('Data Scientist')\n",
    "\n",
    "location = driver.find_element(By.XPATH,\"/html/body/div[1]/div[7]/div/div/div[5]/div/div/div/div[1]/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c85aed1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cc217f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make empty list\n",
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "experience_required  = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af59505b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping Job title from the given page\n",
    "title_tags = driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title = i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "#scraping Job location from the given page\n",
    "location_tags = driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location = i.text\n",
    "    job_location.append(location)\n",
    "\n",
    "#scraping company name from the given page\n",
    "company_tags = driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in company_tags[0:10]:\n",
    "    company = i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "#scraping Job experience from the given page\n",
    "experience_tags = driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience = i.text\n",
    "    experience_required.append(experience)\n",
    "                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb94c376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title))\n",
    "print(len(job_location))\n",
    "print(len(company_name))\n",
    "print(len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39f0bd45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Permanent Opportunity - Data Scientist(Snaplog...</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru, Kolkata, Hyderab...</td>\n",
       "      <td>Deloitte</td>\n",
       "      <td>9-14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Machine Learning (AI) Architect</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...</td>\n",
       "      <td>Persistent</td>\n",
       "      <td>5-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Staff Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/ Bengaluru, Karnataka</td>\n",
       "      <td>Tata Consultancy Services (TCS)</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hiring For Data Scientist</td>\n",
       "      <td>Hybrid - Bangalore/ Bengaluru, Karnataka, Hyde...</td>\n",
       "      <td>Tata Consultancy Services (TCS)</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru, Pune, Delhi / NC...</td>\n",
       "      <td>Infogain</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Director/Senior Director - Data Science</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Hyderabad/Secunder...</td>\n",
       "      <td>Axtria India</td>\n",
       "      <td>10-15 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Manager/Senior Manager - Data Science</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Hyderabad/Secunder...</td>\n",
       "      <td>Axtria India</td>\n",
       "      <td>8-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Ericsson</td>\n",
       "      <td>5-7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0  Permanent Opportunity - Data Scientist(Snaplog...   \n",
       "1                   Analystics & Modeling Specialist   \n",
       "2                    Machine Learning (AI) Architect   \n",
       "3                               Staff Data Scientist   \n",
       "4                                     Data Scientist   \n",
       "5                          Hiring For Data Scientist   \n",
       "6                                     Data Scientist   \n",
       "7            Director/Senior Director - Data Science   \n",
       "8              Manager/Senior Manager - Data Science   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                        Job Location  \\\n",
       "0  Hybrid - Bangalore/Bengaluru, Kolkata, Hyderab...   \n",
       "1  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...   \n",
       "2  Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                    Bangalore/ Bengaluru, Karnataka   \n",
       "5  Hybrid - Bangalore/ Bengaluru, Karnataka, Hyde...   \n",
       "6  Hybrid - Bangalore/Bengaluru, Pune, Delhi / NC...   \n",
       "7  Bangalore/Bengaluru, Noida, Hyderabad/Secunder...   \n",
       "8  Bangalore/Bengaluru, Noida, Hyderabad/Secunder...   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                      Company Name Experience  \n",
       "0                         Deloitte   9-14 Yrs  \n",
       "1                        Accenture    6-8 Yrs  \n",
       "2                       Persistent   5-12 Yrs  \n",
       "3                          Walmart    6-8 Yrs  \n",
       "4  Tata Consultancy Services (TCS)    4-8 Yrs  \n",
       "5  Tata Consultancy Services (TCS)    4-9 Yrs  \n",
       "6                         Infogain    3-6 Yrs  \n",
       "7                     Axtria India  10-15 Yrs  \n",
       "8                     Axtria India   8-12 Yrs  \n",
       "9                         Ericsson    5-7 Yrs  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a DataFrame for scraped data\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Job Title':job_title,'Job Location':job_location,'Company Name':company_name,'Experience':experience_required})\n",
    "df\n",
    "\n",
    "#quit the chrome window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242163d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45ce5e53",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get thewebpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results youget.\n",
    "6. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf498af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "350c9354",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Admin\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a390b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62a6cd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the naukri page on automated chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad2c27a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering designation as required in the question-\n",
    "designation = driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3111b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66c2332a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying location filter as “Delhi/NCR”\n",
    "search = driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/div/section[1]/div[2]/div[5]/div[2]/div[2]/label/p/span[1]\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e79de91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying salary filter as “3-6” lakhs\n",
    "search = driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/div/section[1]/div[2]/div[6]/div[2]/div[2]/label/p/span[1]\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3faec4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make empty list\n",
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "experience_required  = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "36d9cb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping Job title from the given page\n",
    "title_tags = driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title = i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "#scraping Job location from the given page\n",
    "location_tags = driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location = i.text\n",
    "    job_location.append(location)\n",
    "\n",
    "#scraping company name from the given page\n",
    "company_tags = driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in company_tags[0:10]:\n",
    "    company = i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "#scraping Job experience from the given page\n",
    "experience_tags = driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience = i.text\n",
    "    experience_required.append(experience)\n",
    "                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a9c3e23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title))\n",
    "print(len(job_location))\n",
    "print(len(company_name))\n",
    "print(len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9769df75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...</td>\n",
       "      <td>Analytos</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Blackbuck</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Jubilant Ingrevia Limited</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...</td>\n",
       "      <td>Analytos</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Python and ML Trainer</td>\n",
       "      <td>Hyderabad/Secunderabad, New Delhi, Pune, Gurga...</td>\n",
       "      <td>Thescholar</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "      <td>Tata Consultancy Services (TCS)</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Intern</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Tower Research Capital</td>\n",
       "      <td>0-1 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lead Assistant Manager</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>EXL</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Innovaccer</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, United States (USA), Bulgaria</td>\n",
       "      <td>Adidas</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Job Title                                       Job Location  \\\n",
       "0   Junior Data Scientist  Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...   \n",
       "1          Data Scientist              Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "2          Data Scientist                                              Noida   \n",
       "3          Data Scientist  Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...   \n",
       "4   Python and ML Trainer  Hyderabad/Secunderabad, New Delhi, Pune, Gurga...   \n",
       "5          Data Scientist                                        Delhi / NCR   \n",
       "6                  Intern                                   Gurgaon/Gurugram   \n",
       "7  Lead Assistant Manager                                   Gurgaon/Gurugram   \n",
       "8          Data Scientist                                              Noida   \n",
       "9   Junior Data Scientist    Gurgaon/Gurugram, United States (USA), Bulgaria   \n",
       "\n",
       "                      Company Name Experience  \n",
       "0                         Analytos    0-2 Yrs  \n",
       "1                        Blackbuck    3-7 Yrs  \n",
       "2        Jubilant Ingrevia Limited    3-8 Yrs  \n",
       "3                         Analytos    2-4 Yrs  \n",
       "4                       Thescholar    3-8 Yrs  \n",
       "5  Tata Consultancy Services (TCS)   7-12 Yrs  \n",
       "6           Tower Research Capital    0-1 Yrs  \n",
       "7                              EXL    2-6 Yrs  \n",
       "8                       Innovaccer    2-4 Yrs  \n",
       "9                           Adidas    1-6 Yrs  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making DataFrame\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Job Title':job_title,'Job Location':job_location,'Company Name':company_name,'Experience':experience_required})\n",
    "df\n",
    "\n",
    "#quit the chrome window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3531185c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7635d65",
   "metadata": {},
   "source": [
    "# Q:4 Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "\n",
    "To scrape the data you have to go through following steps:\n",
    "    \n",
    "1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and\n",
    "   click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the\n",
    "   required data as usual.\n",
    "4. After scraping data from the first page, go to the “Next” Button at the bottom other page , then\n",
    "   click on it.\n",
    "5. Now scrape data from this page as usual\n",
    "6. Repeat this until you get data for 100 sunglasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "920b7029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e575414a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Admin\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dcfce239",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e414382",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the naukri page on automated chrome browser\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b0120b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering sunglasses as required in the question-\n",
    "product = driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "product.send_keys('sunglasses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "09517a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8204a25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make empty list\n",
    "sunglasses_brand = []\n",
    "sunglasses_product_description = []\n",
    "sunglasses_price = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8cab0289",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_tags = driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')   #scaping sunglasses brand from the given page\n",
    "for i in brand_tags[0:25]:\n",
    "    brand = i.text\n",
    "    sunglasses_brand.append(brand)\n",
    "    \n",
    "\n",
    "product_description_tags = driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')  #scraping product description from the given page\n",
    "for i in product_description_tags[0:25]:\n",
    "    description = i.text\n",
    "    sunglasses_product_description.append(description)\n",
    "\n",
    "\n",
    "price_tags = driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')  #scraping price from the given page\n",
    "for i in price_tags[0:25]:\n",
    "    price = i.text\n",
    "    sunglasses_price.append(price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cfb0d57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_button = driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]/span\") #to scrap data from next pages\n",
    "next_button.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a82bb13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_tags = driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')   #scaping sunglasses brand from the given page\n",
    "for i in brand_tags[0:25]:\n",
    "    brand = i.text\n",
    "    sunglasses_brand.append(brand)\n",
    "    \n",
    "\n",
    "product_description_tags = driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')  #scraping product description from the given page\n",
    "for i in product_description_tags[0:25]:\n",
    "    description = i.text\n",
    "    sunglasses_product_description.append(description)\n",
    "\n",
    "\n",
    "price_tags = driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')  #scraping price from the given page\n",
    "for i in price_tags[0:25]:\n",
    "    price = i.text\n",
    "    sunglasses_price.append(price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "38bf7bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_button = driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[12]/span\") #to scrap data from next pages\n",
    "next_button.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bcc12be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_tags = driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')   #scaping sunglasses brand from the given page\n",
    "for i in brand_tags[0:25]:\n",
    "    brand = i.text\n",
    "    sunglasses_brand.append(brand)\n",
    "    \n",
    "\n",
    "product_description_tags = driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')  #scraping product description from the given page\n",
    "for i in product_description_tags[0:25]:\n",
    "    description = i.text\n",
    "    sunglasses_product_description.append(description)\n",
    "\n",
    "\n",
    "price_tags = driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')  #scraping price from the given page\n",
    "for i in price_tags[0:25]:\n",
    "    price = i.text\n",
    "    sunglasses_price.append(price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5122cdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_button = driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[12]/span\") #to scrap data from next pages\n",
    "next_button.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ecf13519",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_tags = driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')   #scaping sunglasses brand from the given page\n",
    "for i in brand_tags[0:25]:\n",
    "    brand = i.text\n",
    "    sunglasses_brand.append(brand)\n",
    "    \n",
    "\n",
    "product_description_tags = driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')  #scraping product description from the given page\n",
    "for i in product_description_tags[0:25]:\n",
    "    description = i.text\n",
    "    sunglasses_product_description.append(description)\n",
    "\n",
    "\n",
    "price_tags = driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')  #scraping price from the given page\n",
    "for i in price_tags[0:25]:\n",
    "    price = i.text\n",
    "    sunglasses_price.append(price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f59446dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(sunglasses_brand))\n",
    "print(len(sunglasses_product_description))\n",
    "print(len(sunglasses_price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "144435ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sunglasses Brand</th>\n",
       "      <th>Sunglasses Product Description</th>\n",
       "      <th>Sunglasses Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OAKLEY</td>\n",
       "      <td>Rectangular Sunglass</td>\n",
       "      <td>₹9,119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>style guru</td>\n",
       "      <td>Mirrored, Night Vision, UV Protection Wayfarer...</td>\n",
       "      <td>₹899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (50)</td>\n",
       "      <td>₹216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BKGE</td>\n",
       "      <td>Polarized, UV Protection Retro Square Sunglass...</td>\n",
       "      <td>₹149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>SUNBEE</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>elegante</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>Polarized, UV Protection Aviator Sunglasses (55)</td>\n",
       "      <td>₹449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Wayfarer ...</td>\n",
       "      <td>₹663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sunglasses Brand                     Sunglasses Product Description  \\\n",
       "0            OAKLEY                               Rectangular Sunglass   \n",
       "1        style guru  Mirrored, Night Vision, UV Protection Wayfarer...   \n",
       "2          Fastrack   UV Protection Rectangular Sunglasses (Free Size)   \n",
       "3              SRPM             UV Protection Wayfarer Sunglasses (50)   \n",
       "4              BKGE  Polarized, UV Protection Retro Square Sunglass...   \n",
       "..              ...                                                ...   \n",
       "95           SUNBEE   UV Protection Rectangular Sunglasses (Free Size)   \n",
       "96         elegante      UV Protection Wayfarer Sunglasses (Free Size)   \n",
       "97           PIRASO              UV Protection Aviator Sunglasses (54)   \n",
       "98   ROZZETTA CRAFT   Polarized, UV Protection Aviator Sunglasses (55)   \n",
       "99    VINCENT CHASE  by Lenskart Polarized, UV Protection Wayfarer ...   \n",
       "\n",
       "   Sunglasses Price  \n",
       "0            ₹9,119  \n",
       "1              ₹899  \n",
       "2              ₹499  \n",
       "3              ₹216  \n",
       "4              ₹149  \n",
       "..              ...  \n",
       "95             ₹195  \n",
       "96             ₹399  \n",
       "97             ₹275  \n",
       "98             ₹449  \n",
       "99             ₹663  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making DataFrame\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Sunglasses Brand':sunglasses_brand,\n",
    "                   'Sunglasses Product Description':sunglasses_product_description,\n",
    "                   'Sunglasses Price':sunglasses_price,})\n",
    "df\n",
    "\n",
    "#close the chrome window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b83fe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e195460",
   "metadata": {},
   "source": [
    "# Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link:\n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART\n",
    "\n",
    "    \n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100reviews.    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "220d0d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0602e303",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Admin\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a576eb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0be0a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the naukri page on automated chrome browser\n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "710f7fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make empty list\n",
    "Rating = []\n",
    "Review_summary = []\n",
    "Full_review = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "452d8159",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "end = 10\n",
    "for page in range(start,end):\n",
    "    rating_tags = driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')   #scaping rating from the given page\n",
    "    for i in rating_tags:\n",
    "        Rating.append(i.text)\n",
    "\n",
    "    review_summary_tags = driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')  #scraping review summary from the given page\n",
    "    for i in review_summary_tags:\n",
    "        Review_summary.append(i.text)\n",
    "\n",
    "\n",
    "    full_review_tags = driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')  #scraping full review from the given page\n",
    "    for i in full_review_tags:\n",
    "        Full_review.append(i.text)\n",
    "        \n",
    "        \n",
    "    next_button = driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]') #to scrap data from next pages\n",
    "    next_button.click()\n",
    "    time.sleep(3)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcbbc554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(Rating))\n",
    "print(len(Review_summary))\n",
    "print(len(Full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49b13613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Value-for-money</td>\n",
       "      <td>I'm Really happy with the product\\nDelivery wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>It's my first time to use iOS phone and I am l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Value for money❤️❤️\\nIts awesome mobile phone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>Amazing camera quality as expected, battery al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>4</td>\n",
       "      <td>Value-for-money</td>\n",
       "      <td>Just got this iphone 11\\nAnd it is most powerf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>It is just awesome mobile for this price from ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating       Review Summary  \\\n",
       "0       5       Simply awesome   \n",
       "1       5     Perfect product!   \n",
       "2       5  Best in the market!   \n",
       "3       4      Value-for-money   \n",
       "4       5   Highly recommended   \n",
       "..    ...                  ...   \n",
       "95      5     Perfect product!   \n",
       "96      5   Highly recommended   \n",
       "97      5   Highly recommended   \n",
       "98      4      Value-for-money   \n",
       "99      5     Perfect product!   \n",
       "\n",
       "                                          Full Review  \n",
       "0   Really satisfied with the Product I received.....  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   I'm Really happy with the product\\nDelivery wa...  \n",
       "4   It's my first time to use iOS phone and I am l...  \n",
       "..                                                ...  \n",
       "95  Value for money❤️❤️\\nIts awesome mobile phone ...  \n",
       "96  iphone 11 is a very good phone to buy only if ...  \n",
       "97  Amazing camera quality as expected, battery al...  \n",
       "98  Just got this iphone 11\\nAnd it is most powerf...  \n",
       "99  It is just awesome mobile for this price from ...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making DataFrame\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Rating':Rating,\n",
    "                   'Review Summary':Review_summary,\n",
    "                   'Full Review':Full_review,})\n",
    "df\n",
    "\n",
    "#close the chrome window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cd8976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ee96659",
   "metadata": {},
   "source": [
    "# Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "You have to scrape 3 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47cc4822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3edb3d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Admin\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b84119b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e4ace89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the naukri page on automated chrome browser\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e6867a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering product as required in the question-\n",
    "product = driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "product.send_keys('sneakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0440f291",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5af9fd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make empty list\n",
    "sneakers_brand = []\n",
    "sneakers_product_description = []\n",
    "sneakers_price = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8588f81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "end = 4\n",
    "for page in range(start,end):\n",
    "    brand_tags = driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')   #scaping sneakers brand from the given page\n",
    "    for i in brand_tags[0:25]:\n",
    "        sneakers_brand.append(i.text)\n",
    "    \n",
    "\n",
    "    product_description_tags = driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')  #scraping sneakers product description from the given page\n",
    "    for i in product_description_tags[0:25]:\n",
    "        sneakers_product_description.append(i.text)\n",
    "\n",
    "\n",
    "    price_tags = driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')  #scraping sneakers price from the given page\n",
    "    for i in price_tags[0:25]:\n",
    "        sneakers_price.append(i.text)\n",
    "        \n",
    "    next_button = driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]') #to scrap data from next pages\n",
    "    next_button.click()\n",
    "    time.sleep(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2c4e029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(sneakers_brand))\n",
    "print(len(sneakers_product_description))\n",
    "print(len(sneakers_price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a1ad90e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sneakers Brand</th>\n",
       "      <th>Sneakers Product Description</th>\n",
       "      <th>Sneakers Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K- FOOTLANCE</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>World Wear Footwear</td>\n",
       "      <td>Trendy Stylish Comfortable &amp; Lightweight, Casu...</td>\n",
       "      <td>₹399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Labbin</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Buzz Sneakers For Men</td>\n",
       "      <td>₹1,149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>asian</td>\n",
       "      <td>Thunder-01 White Color Change Sneakers,Casuals...</td>\n",
       "      <td>₹714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Krors</td>\n",
       "      <td>Styles Men's Fashion Outdoor Trend High Top Sp...</td>\n",
       "      <td>₹549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Combo Pack Of 2 Casual Shoes Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>SUMMITS - BRISBANE Sneakers For Men</td>\n",
       "      <td>₹1,891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>HRX by Hrithik Roshan</td>\n",
       "      <td>Men Street Athleisure Shoe Sneakers For Men</td>\n",
       "      <td>₹1,224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Harrow Wns Sneakers For Women</td>\n",
       "      <td>₹1,049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Sneakers Brand                       Sneakers Product Description  \\\n",
       "0            K- FOOTLANCE                                   Sneakers For Men   \n",
       "1     World Wear Footwear  Trendy Stylish Comfortable & Lightweight, Casu...   \n",
       "2                  Labbin                                   Sneakers For Men   \n",
       "3                    PUMA                              Buzz Sneakers For Men   \n",
       "4                   asian  Thunder-01 White Color Change Sneakers,Casuals...   \n",
       "..                    ...                                                ...   \n",
       "95                  Krors  Styles Men's Fashion Outdoor Trend High Top Sp...   \n",
       "96                 BRUTON      Combo Pack Of 2 Casual Shoes Sneakers For Men   \n",
       "97               Skechers                SUMMITS - BRISBANE Sneakers For Men   \n",
       "98  HRX by Hrithik Roshan        Men Street Athleisure Shoe Sneakers For Men   \n",
       "99                   PUMA                      Harrow Wns Sneakers For Women   \n",
       "\n",
       "   Sneakers Price  \n",
       "0            ₹299  \n",
       "1            ₹399  \n",
       "2            ₹349  \n",
       "3          ₹1,149  \n",
       "4            ₹714  \n",
       "..            ...  \n",
       "95           ₹549  \n",
       "96           ₹399  \n",
       "97         ₹1,891  \n",
       "98         ₹1,224  \n",
       "99         ₹1,049  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#crearting DataFrame for scraped data\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Sneakers Brand':sneakers_brand,\n",
    "                   'Sneakers Product Description':sneakers_product_description,\n",
    "                   'Sneakers Price':sneakers_price,})\n",
    "df\n",
    "\n",
    "#close the chrome window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd415f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6db3b9d8",
   "metadata": {},
   "source": [
    "# Q7: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Thenset CPU Type filter to “Intel Core i7”.\n",
    "\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fec090c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8cf94896",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Admin\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b18f5de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b805898",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the amazon page on automated chrome browser\n",
    "driver.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d74ee858",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering product as required in the question-\n",
    "product = driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input\")\n",
    "product.send_keys('Laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f08c16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1be9832",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying location filter as “Intel Core i7”\n",
    "search = driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[6]/ul[6]/span[11]/li/span/a/span\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dbfbfced",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make empty list\n",
    "Title = []\n",
    "Ratings = []\n",
    "Price = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3358922",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tags = driver.find_elements(By.XPATH,'//span[@class=\"a-size-medium a-color-base a-text-normal\"]')   #scaping laptop title from the given page\n",
    "for i in title_tags[0:10]:\n",
    "    Title.append(i.text)\n",
    "    \n",
    "\n",
    "ratings_tags = driver.find_elements(By.XPATH,'//i[@class=\"a-icon a-icon-star-small a-star-small-4 aok-align-bottom\"]')  #scraping laptop ratings from the given page\n",
    "for i in ratings_tags[0:10]:\n",
    "    Ratings.append(i.text)\n",
    "\n",
    "\n",
    "price_tags = driver.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]')  #scraping laptop price from the given page\n",
    "for i in price_tags[0:10]:\n",
    "    Price.append(i.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62a1ff74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(Title))\n",
    "print(len(Ratings))\n",
    "print(len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "69ddba02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Laptop Title</th>\n",
       "      <th>Laptop Ratings</th>\n",
       "      <th>Laptop Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HP Laptop 15s, 12th Gen Intel Core i7-1255U, 1...</td>\n",
       "      <td></td>\n",
       "      <td>70,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenovo ThinkPad E14 Intel Core i7 12th Gen 14\"...</td>\n",
       "      <td></td>\n",
       "      <td>98,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acer Predator Helios Neo 16 Gaming Laptop 13th...</td>\n",
       "      <td></td>\n",
       "      <td>1,29,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...</td>\n",
       "      <td></td>\n",
       "      <td>79,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP Victus Gaming Latest 12th Gen Intel Core i7...</td>\n",
       "      <td></td>\n",
       "      <td>90,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HP Envy x360 12th Gen Intel Core i7-13.3 inch(...</td>\n",
       "      <td></td>\n",
       "      <td>1,03,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ASUS TUF Gaming F15 (2023) 90WHr Battery, Inte...</td>\n",
       "      <td></td>\n",
       "      <td>1,15,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dell G15-5530 Gaming Laptop, Intel Core i7-136...</td>\n",
       "      <td></td>\n",
       "      <td>1,31,860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...</td>\n",
       "      <td></td>\n",
       "      <td>84,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ASUS TUF Gaming F15 (2022), 15.6\"(39.62 cms) F...</td>\n",
       "      <td></td>\n",
       "      <td>93,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Laptop Title Laptop Ratings  \\\n",
       "0  HP Laptop 15s, 12th Gen Intel Core i7-1255U, 1...                  \n",
       "1  Lenovo ThinkPad E14 Intel Core i7 12th Gen 14\"...                  \n",
       "2  Acer Predator Helios Neo 16 Gaming Laptop 13th...                  \n",
       "3  Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...                  \n",
       "4  HP Victus Gaming Latest 12th Gen Intel Core i7...                  \n",
       "5  HP Envy x360 12th Gen Intel Core i7-13.3 inch(...                  \n",
       "6  ASUS TUF Gaming F15 (2023) 90WHr Battery, Inte...                  \n",
       "7  Dell G15-5530 Gaming Laptop, Intel Core i7-136...                  \n",
       "8  HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...                  \n",
       "9  ASUS TUF Gaming F15 (2022), 15.6\"(39.62 cms) F...                  \n",
       "\n",
       "  Laptop Price  \n",
       "0       70,990  \n",
       "1       98,990  \n",
       "2     1,29,990  \n",
       "3       79,990  \n",
       "4       90,990  \n",
       "5     1,03,990  \n",
       "6     1,15,990  \n",
       "7     1,31,860  \n",
       "8       84,999  \n",
       "9       93,990  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#crearting DataFrame for scraped data\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Laptop Title':Title,\n",
    "                   'Laptop Ratings':Ratings,\n",
    "                   'Laptop Price':Price,})\n",
    "df\n",
    "\n",
    "#close the chrome window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea75513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6f4490e",
   "metadata": {},
   "source": [
    "# Q8: Write a python program to scrape data for Top 1000 Quotes of All Time.\n",
    "\n",
    "The above task will be done in following steps:\n",
    "1. First get the webpage https://www.azquotes.com/\n",
    "2. Click on Top Quotes\n",
    "3. scrap \n",
    "a) Quote\n",
    "b) Author \n",
    "c) Type Of Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd321c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "69817d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Admin\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "35d4279d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c3cd97a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the amazon page on automated chrome browser\n",
    "driver.get(\"https://www.azquotes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aa5f394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click for Top Quotes\n",
    "search = driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/div[1]/div/div[3]/ul/li[5]/a\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "977d805d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make empty list\n",
    "Quote = []\n",
    "Author = []\n",
    "Types = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d1abc84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "end = 10\n",
    "for page in range(start,end):\n",
    "    Quote_tags = driver.find_elements(By.XPATH,'//a[@class=\"title\"]')   #scaping Quotes from the given page\n",
    "    for i in Quote_tags[0:100]:\n",
    "        Quote.append(i.text)\n",
    "    \n",
    "\n",
    "    Author_tags = driver.find_elements(By.XPATH,'//div[@class=\"author\"]')  #scraping Author from the given page\n",
    "    for i in Author_tags[0:100]:\n",
    "        Author.append(i.text)\n",
    "\n",
    "\n",
    "    Types_tags = driver.find_elements(By.XPATH,'//div[@class=\"tags\"]')  #scraping Types of Quotes from the given page\n",
    "    for i in Types_tags[0:100]:\n",
    "        Types.append(i.text)\n",
    "    \n",
    "    \n",
    "    next_button = driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[3]/li[12]\") #to scrap data from next pages\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ff311f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(Quote))\n",
    "print(len(Author))\n",
    "print(len(Types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8aa0101b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top Quotes</th>\n",
       "      <th>Author of Quote</th>\n",
       "      <th>Types of Quote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The essence of strategy is choosing what not t...</td>\n",
       "      <td>Michael Porter</td>\n",
       "      <td>Essence, Deep Thought, Transcendentalism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One cannot and must not try to erase the past ...</td>\n",
       "      <td>Golda Meir</td>\n",
       "      <td>Inspiration, Past, Trying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patriotism means to stand by the country. It d...</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>Country, Peace, War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Death is something inevitable. When a man has ...</td>\n",
       "      <td>Nelson Mandela</td>\n",
       "      <td>Inspirational, Motivational, Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You have to love a nation that celebrates its ...</td>\n",
       "      <td>Erma Bombeck</td>\n",
       "      <td>4th Of July, Food, Patriotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Regret for the things we did can be tempered b...</td>\n",
       "      <td>Sydney J. Harris</td>\n",
       "      <td>Love, Inspirational, Motivational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>America... just a nation of two hundred millio...</td>\n",
       "      <td>Hunter S. Thompson</td>\n",
       "      <td>Gun, Two, Qualms About</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>For every disciplined effort there is a multip...</td>\n",
       "      <td>Jim Rohn</td>\n",
       "      <td>Inspirational, Greatness, Best Effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The spiritual journey is individual, highly pe...</td>\n",
       "      <td>Ram Dass</td>\n",
       "      <td>Spiritual, Truth, Yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>The mind is not a vessel to be filled but a fi...</td>\n",
       "      <td>Plutarch</td>\n",
       "      <td>Inspirational, Leadership, Education</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Top Quotes     Author of Quote  \\\n",
       "0    The essence of strategy is choosing what not t...      Michael Porter   \n",
       "1    One cannot and must not try to erase the past ...          Golda Meir   \n",
       "2    Patriotism means to stand by the country. It d...  Theodore Roosevelt   \n",
       "3    Death is something inevitable. When a man has ...      Nelson Mandela   \n",
       "4    You have to love a nation that celebrates its ...        Erma Bombeck   \n",
       "..                                                 ...                 ...   \n",
       "995  Regret for the things we did can be tempered b...    Sydney J. Harris   \n",
       "996  America... just a nation of two hundred millio...  Hunter S. Thompson   \n",
       "997  For every disciplined effort there is a multip...            Jim Rohn   \n",
       "998  The spiritual journey is individual, highly pe...            Ram Dass   \n",
       "999  The mind is not a vessel to be filled but a fi...            Plutarch   \n",
       "\n",
       "                               Types of Quote  \n",
       "0    Essence, Deep Thought, Transcendentalism  \n",
       "1                   Inspiration, Past, Trying  \n",
       "2                         Country, Peace, War  \n",
       "3          Inspirational, Motivational, Death  \n",
       "4                4th Of July, Food, Patriotic  \n",
       "..                                        ...  \n",
       "995         Love, Inspirational, Motivational  \n",
       "996                    Gun, Two, Qualms About  \n",
       "997     Inspirational, Greatness, Best Effort  \n",
       "998                    Spiritual, Truth, Yoga  \n",
       "999      Inspirational, Leadership, Education  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#crearting DataFrame for scraped data\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Top Quotes':Quote,\n",
    "                   'Author of Quote':Author,\n",
    "                   'Types of Quote':Types,})\n",
    "df\n",
    "\n",
    "#close the chrome window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9c5b06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "963ca83b",
   "metadata": {},
   "source": [
    "# Q9: Write a python program to display list of respected former Prime Ministers of India(i.e. Name, Born-Dead, Term of office, Remarks) from https://www.jagranjosh.com/.\n",
    "\n",
    "This task will be done in following steps:\n",
    "1. First get the webpagehttps://www.jagranjosh.com/\n",
    "2. Then You have to click on the GK option\n",
    "3. Then click on the List of all Prime Ministers of India\n",
    "4. Then scrap the mentioned data and make theDataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aaf95538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dbfd3b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Admin\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d3d76916",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fab7aeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the amazon page on automated chrome browser\n",
    "driver.get(\"https://www.jagranjosh.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e75f7115",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click for GK option\n",
    "search = driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/div/div[1]/div/div[5]/div/div[1]/header/div[3]/ul/li[3]/a\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "10ea3ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click for list of all prime ministers of India\n",
    "search = driver.find_element(By.XPATH,\"/html/body/div[1]/div/div/div[2]/div/div[10]/div/div/ul/li[2]/a\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6e2b6558",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make empty list\n",
    "Data = []\n",
    "Class = []\n",
    "Name = []\n",
    "Born_Dead = []\n",
    "Term_of_Office = []\n",
    "Remark = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "86a48daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Class_tags = driver.find_elements(By.XPATH,'//div[@class=\"table-box\"]')\n",
    "for i in Class_tags:\n",
    "    Class.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c9b6b4b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"S.N.\\nName\\nBorn-Dead\\nTerm of office\\nRemark\\n1.\\nJawahar Lal Nehru\\n(1889–1964)\\n15 August 1947 to 27 May 1964\\n16 years, 286 days\\nThe first prime minister of India and the longest-serving PM of India, the first to die in office.\\n2.\\nGulzarilal Nanda (Acting)\\n(1898-1998)\\n27 May 1964 to 9 June 1964,\\n13 days\\nFirst acting PM of India\\n3.\\nLal Bahadur Shastri\\n(1904–1966)\\n9 June 1964 to 11 January 1966\\n1 year, 216 days\\nHe has given the slogan of 'Jai Jawan Jai Kisan' during the Indo-Pak war of 1965\\n4. \\nGulzari Lal Nanda  (Acting)\\n(1898-1998)\\n11 January 1966 to 24 January 1966\\n13 days\\n-\\n5.\\nIndira Gandhi\\n(1917–1984)\\n24 January 1966 to 24 March 1977\\n11 years, 59 days\\nFirst female Prime Minister of India\\n6.\\nMorarji Desai\\n(1896–1995)\\n24 March 1977 to  28 July 1979 \\n2 year, 126 days\\nOldest to become PM (81 years old) and first to resign from office\\n7.\\nCharan Singh\\n(1902–1987)\\n28 July 1979 to 14 January 1980\\n170 days\\nOnly PM who did not face the Parliament\\n8.\\nIndira Gandhi\\n(1917–1984)\\n14 January 1980 to 31 October 1984\\n4 years, 291 days\\nThe first lady who served as PM for the second term\\n9.\\nRajiv Gandhi\\n(1944–1991)\\n31 October 1984 to 2 December 1989\\n5 years, 32 days\\nYoungest to become PM (40 years old)\\n10.\\nV. P. Singh\\n(1931–2008)\\n2 December 1989 to 10 November 1990\\n343 days\\nFirst PM to step down after a vote of no confidence\\n11.\\nChandra Shekhar\\n(1927–2007)\\n10 November 1990 to 21 June 1991\\n223 days\\nHe belongs to  Samajwadi Janata Party\\n12.\\nP. V. Narasimha Rao\\n(1921–2004)\\n21 June 1991 to 16 May 1996\\n4 years, 330 days\\nFirst PM from South India\\n13.\\nAtal Bihari Vajpayee\\n(1924- 2018)\\n16 May 1996 to 1 June 1996\\n16 days\\nPM for shortest tenure\\n14.\\nH. D. Deve Gowda\\n(born 1933)\\n1 June 1996 to 21 April 1997\\n324 days\\nHe belongs to  Janata Dal\\n15.\\nInder Kumar Gujral\\n(1919–2012)\\n21 April 1997 to 19 March 1998 \\n332 days\\n------\\n16.\\nAtal Bihari Vajpayee\\n(1924-2018)\\n19 March 1998 to 22 May 2004 \\n6 years, 64 days\\n The first non-congress PM who completed a full term as PM\\n17.\\nManmohan Singh\\n(born 1932)\\n22 May 2004 to 26 May 2014   \\n10 years, 4 days\\n First Sikh PM\\n18.\\nNarendra Modi\\n(born 1950)\\n26 May 2014 - 2019\\n4th Prime Minister of India who served two consecutive tenures\\n19.\\nNarendra Modi\\n(born 1950)\\n30 May 2019- Incumbent\\nFirst non-congress PM with two consecutive tenures\",\n",
       " 'List of all Presidents of India List of Nicknames of Indian Prime Ministers']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db977e18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53c9eb16",
   "metadata": {},
   "source": [
    "# Q10: Write a python program to display list of 50 Most expensive cars in the world (i.e. Car name and Price) from https://www.motor1.com/\n",
    "        \n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.motor1.com/\n",
    "2. Then You have to type in the search bar ’50 most expensive cars’\n",
    "3. Then click on 50 most expensive cars in the world..\n",
    "4. Then scrap the mentioned data and make the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7530b10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "41b2da2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Admin\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "58ec6efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cfbb7f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the amazon page on automated chrome browser\n",
    "driver.get(\"https://www.motor1.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26179306",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0f181cd6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_all_ele' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16884\\1108930900.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#extract titles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mc_titles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_all_ele\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'//h3[@class=\"\"subheader]'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#define variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_all_ele' is not defined"
     ]
    }
   ],
   "source": [
    "#extract titles\n",
    "\n",
    "c_titles = get_all_ele(1,'//h3[@class=\"\"subheader]',0)\n",
    "\n",
    "#define variables\n",
    "\n",
    "start = 4\n",
    "jump = 2\n",
    "end = start + (jump*len(c_titles))\n",
    "c_price = []\n",
    "\n",
    "#extract price tag\n",
    "\n",
    "for i in range(start,end,jump):\n",
    "    \n",
    "    x = '/html/body/div[3]/div[7]/div[2]/div[1],div[2]/div[1]/p[' +str(i) +']'\n",
    "    y = get_all_ele(1,x,0)\n",
    "    c_price.append(y)\n",
    "    \n",
    "#creating dictionary from list of elements extracted\n",
    "\n",
    "car_dict = {'Car Name':c_title[0:50],'Price':c_price[0:50]}\n",
    "\n",
    "#craeting DataFrame to scraped data\n",
    "\n",
    "car_df = pd.DataFrame(Car_dict)\n",
    "car_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e8ac32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
